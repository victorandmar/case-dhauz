{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case t√©cnico DHAUZ - Modelagem de cancelamentos\n",
    "Victor Andrade Martins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Briefing**: Voc√™ foi contratado pela DHAUZ como cientista de dados para analisar uma base de dados de clientes de uma rede de Hot√©is e sua tarefa √© investigar os dados em busca de insights que possam ajudar a empresa a evitar cancelamentos e tamb√©m construir um modelo preditivo que possa antecipar esses cancelamentos, de modo que a empresa tenha tempo h√°bil para agir com a√ß√µes de reten√ß√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enquanto leem o estudo, incentivo a tamb√©m darem uma olhada no app que desenvolvi para case: https://victorandmar-case-dhauz-app-dhauz-3n813c.streamlitapp.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualiza√ß√£o\n",
    "import plotly.graph_objects as go\n",
    "from plotly.colors import n_colors\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode()\n",
    "\n",
    "# Correla√ß√£o\n",
    "import association_metrics as am\n",
    "\n",
    "# Processamento\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Separa√ß√£o\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modelos para classifica√ß√£o\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Afinamento\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Avalia√ß√£o de modelos\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cancellation-prediction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An√°lise Explorat√≥ria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para lidar com os valores nulos, ser√° atribu√≠do 0 aos registros que n√£o possuem quantidade de crian√ßas (coluna *num_children*). Em rela√ß√£o aos nulos da coluna pa√≠s, ser√° avaliada a necessidade dessa informa√ß√£o antes de descartar esses registros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_children'] = df['num_children'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listagem de colunas num√©ricas\n",
    "nums = [\n",
    "    'days_between_booking_arrival', 'changes_between_booking_arrival',\n",
    "    'num_adults', 'num_children', 'num_babies', 'num_weekend_nights',\n",
    "    'num_workweek_nights', 'num_previous_cancellations', 'num_previous_stays',\n",
    "    'required_car_parking_spaces', 'total_of_special_requests', 'avg_price',\n",
    "]\n",
    "\n",
    "df[nums] = df[nums].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listagem de colunas nominais\n",
    "noms = [\n",
    "    'cancellation', 'type', 'year_arrival_date', 'month_arrival_date',\n",
    "    'week_number_arrival_date', 'day_of_month_arrival_date', 'deposit_policy',\n",
    "    'country', 'breakfast', 'market_segment', 'distribution_channel',\n",
    "    'customer_type'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[nums].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    (antes de construir os gr√°ficos interativos, eu montei uma paleta personalizada com algumas cores do site da DHAUZ.     Fiquem √† vontade para anotar os c√≥digos hexadecimais üòâ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paleta com as cores da DHAUZ\n",
    "paleta_dhauz = [\n",
    "   '#7b3afa','#4e28a0','#efeef2','#17e5fd', '#a478fc', '#42d0e1', '#46405f'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.pie(df,\n",
    "             names='cancellation',\n",
    "             color_discrete_sequence=paleta_dhauz,\n",
    "             hole=.3,\n",
    "             template='ggplot2')\n",
    "\n",
    "fig.update_layout(title='Contagem de cancelamentos', showlegend=False)\n",
    "\n",
    "fig.update_traces(textinfo='value+percent+label',\n",
    "                  marker=dict(line=dict(color='white', width=3)))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao analisar o gr√°fico acima, percebe-se que o dataset √© desbalanceado. O r√≥tulo 0 (n√£o cancelou) est√° muito mais presente no conjunto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correla√ß√µes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correla√ß√µes nominais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para analisar a correla√ß√£o entre as vari√°veis nominais do conjunto, ser√° utilizado o m√©todo *Cram√©r's-V* ($œÜc$). Como ressalva, √© importante lembrar que esta f√≥rumula apresenta um problema de simetria, que se resume ao fato de que uma vari√°vel x pode explicar y, mas n√£o o contr√°rio. Informa√ß√µes que expliquem por outra perspectiva como duas vari√°veis se relacionam podem ser perdidas devido √† este problema, portanto analisar a correla√ß√£o entre vari√°veis nominais atrav√©s de outros m√©todos (como *Theil's U*) tamb√©m √© interessante, mas por fins pr√°ticos ser√° aplicado o *Cram√©r's-V*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df[noms][:]\n",
    "\n",
    "df_corr = df_corr.dropna(subset='country')\n",
    "\n",
    "df_corr = df_corr.apply(lambda x: pd.factorize(x)[0])\n",
    "\n",
    "df_corr = df_corr.apply(lambda x: x.astype('str'))\n",
    "\n",
    "df_corr = df_corr.apply(lambda x: x.astype(\"category\")\n",
    "                        if x.dtype == \"O\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cramers_v = am.CramersV(df_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfit = cramers_v.fit().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(cfit,\n",
    "                text_auto=True,\n",
    "                aspect='auto',\n",
    "                color_continuous_scale=px.colors.sequential.dense)\n",
    "\n",
    "fig.update_layout(title='Matriz de correla√ß√£o nominal (Cram√©rs V)')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pode-se notar que certas informa√ß√µes possuem forte correla√ß√£o com a vari√°vel de cancelamento. A que mais chama aten√ß√£o √© a *deposit_policy* (0.48), o que intuitivamente faz sentido, tendo em vista que esta vari√°vel provavlmente rege as normas de cancelamento e estorno. Qualquer vari√°vel apresentando correla√ß√£o acima de 0.11 ser√° testada nos modelos preditivos, com exce√ß√£o da *distribution_channel*, que por ser bem explicada pela *market_segment*, teria um uso redundante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_vars = list(cfit['cancellation'][1:].loc[lambda x: x > 0.11].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_vars.remove('distribution_channel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correla√ß√£o entre vari√°vel nominal x num√©ricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J√° para medir a correla√ß√£o entre a nossa vari√°vel de interesse e as outras vari√°veis num√©ricas do conjunto, a f√≥rmula *correlation ratio* ($Œ∑$) ser√° utilizada. Em sumo, esse m√©todo observa como as dispers√µes estat√≠sticas se comportam em cada categoria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_ratio(categories, measurements):\n",
    "    fcat, _ = pd.factorize(categories)\n",
    "    cat_num = np.max(fcat)+1\n",
    "    y_avg_array = np.zeros(cat_num)\n",
    "    n_array = np.zeros(cat_num)\n",
    "    for i in range(0,cat_num):\n",
    "        cat_measures = measurements[np.argwhere(fcat == i).flatten()]\n",
    "        n_array[i] = len(cat_measures)\n",
    "        y_avg_array[i] = np.average(cat_measures)\n",
    "    y_total_avg = np.sum(np.multiply(y_avg_array,n_array))/np.sum(n_array)\n",
    "    numerator = np.sum(np.multiply(n_array,np.power(np.subtract(y_avg_array,y_total_avg),2)))\n",
    "    denominator = np.sum(np.power(np.subtract(measurements,y_total_avg),2))\n",
    "    if numerator == 0:\n",
    "        eta = 0.0\n",
    "    else:\n",
    "        eta = np.sqrt(numerator/denominator)\n",
    "    return eta.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = {}\n",
    "\n",
    "for col in nums:\n",
    "    c = correlation_ratio(df['cancellation'], df[col])\n",
    "    corrs[col] = c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A maior correla√ß√£o observada foi com a vari√°vel que cont√©m a informa√ß√£o dos dias faltantes at√© a reserva (*days_between_booking_arrival*). Como j√° selecionamos muitas vari√°veis, apenas as principais (corr >= 0.2) desse grupo ser√£o escolhidas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars = [\n",
    "    'days_between_booking_arrival', 'total_of_special_requests',\n",
    "    'required_car_parking_spaces'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para lidar com os outliers nominais, ser√° removida toda varia√ß√£o de nominais com menos de 130 registros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in nom_vars:\n",
    "    counts = df[col].value_counts().loc[lambda x: x > 130].index\n",
    "    df = df.loc[df[col].isin(counts)][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisando as vari√°veis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segmento de mercado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df,\n",
    "                   x='market_segment',\n",
    "                   color='market_segment',\n",
    "                   color_discrete_sequence=paleta_dhauz,\n",
    "                   template='plotly_white')\n",
    "\n",
    "fig.update_layout(title='Distribui√ß√£o dos segmentos de mercado', showlegend=False)\n",
    "\n",
    "fig.update_xaxes(type='category')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df,\n",
    "                   x='market_segment',\n",
    "                   color='cancellation',\n",
    "                   barnorm='percent',\n",
    "                   text_auto='.2f',\n",
    "                   color_discrete_sequence=paleta_dhauz[::-1],\n",
    "                   template='plotly_white')\n",
    "\n",
    "fig.update_layout(title='Taxa de cancelamento por segmento de mercado',\n",
    "                  bargap=0.2)\n",
    "\n",
    "fig.update_yaxes(ticksuffix=\"%\")\n",
    "\n",
    "fig.update_xaxes(type='category')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao analisar os segmentos de mercado, fica evidente que entre alguns deles h√° uma grande varia√ß√£o das taxas de cancelamento. A diferen√ßa entre o m√≠nimo (38,41%) e o m√°ximo (87,72%) √© de quase 50%. Pode-se afirmar que essa vari√°vel ajuda bastante a explicar o cancelamento, uma vez que a probabilidade de uma reserva ser cancelada no segmento 5 √© muito maior do que no segmento 4, por exemplo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pol√≠tica de dep√≥sito (ou reembolso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df,\n",
    "                   x='deposit_policy',\n",
    "                   color='cancellation',\n",
    "                   barnorm='percent',\n",
    "                   text_auto='.2f',\n",
    "                   color_discrete_sequence=paleta_dhauz[::-1],\n",
    "                   template='plotly_white')\n",
    "\n",
    "fig.update_layout(title='Taxa de cancelamento por pol√≠tica de dep√≥sito',\n",
    "                  bargap=0.2)\n",
    "\n",
    "fig.update_yaxes(ticksuffix=\"%\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df,\n",
    "                   x='deposit_policy',\n",
    "                   color='deposit_policy',\n",
    "                   color_discrete_sequence=paleta_dhauz,\n",
    "                   template='plotly_white')\n",
    "\n",
    "fig.update_layout(title='Distribui√ß√£o das pol√≠ticas de dep√≥sito', showlegend=False)\n",
    "\n",
    "fig.update_xaxes(type='category')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canceladas = df['deposit_policy'].loc[df['cancellation']==1]\n",
    "print('Porcentagem das pol√≠ticas de dep√≥sito para reservas canceladas:')\n",
    "print(round(canceladas.value_counts()/len(canceladas)*100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algo interessante a se observar nos gr√°ficos de barras acima √© que dentre as reservas que exigiam dep√≥sito (~11,8%), quase 100% n√£o garantia reembolso e praticamente todas foram canceladas. Al√©m do mais, na parcela fracion√°ria de dep√≥sitos com direito a reembolso, a maioria (80%) n√£o cancelou. Tendo dito isso, a maioria dos cancelamentos (68,4%) n√£o exigia dep√≥sito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pa√≠s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df,\n",
    "                   x='country',\n",
    "                   histnorm='percent',\n",
    "                   color_discrete_sequence=paleta_dhauz[::-1],\n",
    "                   template='plotly_white')\n",
    "\n",
    "fig.update_layout(title='Distribui√ß√£o dos pa√≠ses',\n",
    "                  bargap=0.2)\n",
    "\n",
    "fig.update_yaxes(ticksuffix=\"%\")\n",
    "fig.update_xaxes(categoryorder='total descending')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pode-se notar que existe um c√≥digo ISO com 2 letras correspondente a China (CN). Essa varia√ß√£o ser√° normalizada para corresponder ao c√≥digo ISO da China de 3 letras (CHN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['country']=='CN', 'country'] = 'CHN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df,\n",
    "                   x='country',\n",
    "                   color='cancellation',\n",
    "                   barmode='overlay',\n",
    "                   histnorm='percent',\n",
    "                   text_auto='.2f',\n",
    "                   color_discrete_sequence=paleta_dhauz[::-1],\n",
    "                   template='plotly_white')\n",
    "\n",
    "fig.update_layout(title='Categorias distribu√≠das por pa√≠s',\n",
    "                  bargap=0.2)\n",
    "\n",
    "fig.update_yaxes(ticksuffix=\"%\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(df,\n",
    "                   x='country',\n",
    "                   color='cancellation',\n",
    "                   barnorm='percent',\n",
    "                   text_auto='.2f',\n",
    "                   color_discrete_sequence=paleta_dhauz[::-1],\n",
    "                   template='plotly_white')\n",
    "\n",
    "fig.update_layout(title='Taxa de cancelamento por pa√≠s',\n",
    "                  bargap=0.2)\n",
    "\n",
    "fig.update_yaxes(ticksuffix=\"%\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df,\n",
    "                   x='country',\n",
    "                   color='deposit_policy',\n",
    "                   barnorm='percent',\n",
    "                   text_auto='.2f',\n",
    "                   color_discrete_sequence=paleta_dhauz[::-1],\n",
    "                   template='plotly_white')\n",
    "\n",
    "fig.update_layout(title='Propor√ß√£o de pol√≠ticas de dep√≥sito por pa√≠s',\n",
    "                  bargap=0.2)\n",
    "\n",
    "fig.update_yaxes(ticksuffix=\"%\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A maioria das reservas (41,25%) est√° concentrada em Portugal, assim como a grande maioria dos cancelamentos (62,25%). Inclsuive, o pa√≠s em quest√£o possui a segunda maior taxa de cancelamento, que √© bem alta quando comparada √†s outras. Al√©m do mais, ao analisar a propor√ß√£o de pol√≠ticas de dep√≥sito de cada pa√≠s, pode-se notar uma alta bastante at√≠pica de pol√≠ticas de n√£o-reembolso em Portugal, indicando que esse tipo de regra seja mais comum nos hot√©is do pa√≠s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anteced√™ncia do cancelamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df.loc[df['cancellation']==1],\n",
    "                   x='days_between_booking_arrival',\n",
    "                   barmode='overlay',\n",
    "                   color_discrete_sequence=paleta_dhauz,\n",
    "                   nbins=600,\n",
    "                   template='plotly_white')\n",
    "\n",
    "fig.update_layout(title='Distribui√ß√£o da anteced√™ncia de reservas canceladas',\n",
    "                  bargap=0.1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao analisar a distribui√ß√£o da anteced√™ncia de cancelamento acima, podemos notar que muito cancelamentos s√£o feitos no mesmo dia ou pr√≥ximos √† reserva, e quanto maior a anteced√™ncia, menor a chance da reserva ser cancelada. Para remover os outliers (anteced√™ncias muito grandes) ser√° utilizado o quantil 95% da vari√°vel em quest√£o. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q95 = df['days_between_booking_arrival'].quantile(0.95)\n",
    "q95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['days_between_booking_arrival']<=q95]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pedidos especiais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df,\n",
    "                   x='total_of_special_requests',\n",
    "                   color='cancellation',\n",
    "                   barmode='overlay',\n",
    "                   color_discrete_sequence=paleta_dhauz,\n",
    "                   template='plotly_white')\n",
    "\n",
    "fig.update_layout(title='Taxa de cancelamento por n√∫mero de pedidos especiais',\n",
    "                  bargap=0.2)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acordo com o gr√°fico de barras acima, reservas com pedidos especiais possuem muito menos chance de serem canceladas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vagas de carro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df,\n",
    "                   x='required_car_parking_spaces',\n",
    "                   color='cancellation',\n",
    "                   barmode='overlay',\n",
    "                   color_discrete_sequence=paleta_dhauz,\n",
    "                   template='plotly_white')\n",
    "\n",
    "fig.update_layout(title='Taxa de cancelamento por exig√™ncia de vaga de carro',\n",
    "                  bargap=0.2)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segundo a distribui√ß√£o acima, como os cancelamentos foram feitos apenas por reservas que n√£o exigiam vaga de carro, a vari√°vel em quest√£o pode ser resumida em uma boleana para explicar as reservas canceladas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bool_requires_car_parking_spaces'] = 0\n",
    "df.loc[df['required_car_parking_spaces'] > 0, 'bool_requires_car_parking_spaces'] = 1\n",
    "\n",
    "nom_vars.append('bool_requires_car_parking_spaces')\n",
    "num_vars.remove('required_car_parking_spaces')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desenvolvimento de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seguintes vari√°veis ser√£o utilizadas para teinar os classificadores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nom_vars+num_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[nom_vars + num_vars]\n",
    "\n",
    "X = pd.get_dummies(X, columns=nom_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X[num_vars] = scaler.fit_transform(X[num_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['cancellation']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tamanho dos conjuntos\\n', '\\nTreino:', len(X_train), '\\nTeste:', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sele√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ap√≥s processar e separar o conjunto entre teste e treino, os algoritmos de classifica√ß√£o da lista a seguir foram selecionados para fase de teste. Nesta fase, o processo de valida√ß√£o cruzada √© aplicado e o algoritmo com melhores resultados √© selecionado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista com os algoritmos a serem testados\n",
    "models = [\n",
    "    RandomForestClassifier(random_state=0),\n",
    "    LinearSVC(random_state=0, class_weight='balanced'),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0, class_weight='balanced', max_iter=3000),\n",
    "]\n",
    "\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "\n",
    "for model in models:\n",
    "  model_name = model.__class__.__name__\n",
    "  accuracies = cross_val_score(model, X, y, scoring='accuracy', cv=CV)    # cross validation\n",
    "  for fold_idx, accuracy in enumerate(accuracies):\n",
    "    entries.append((model_name, fold_idx, accuracy))\n",
    "\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df['accuracy'] = cv_df['accuracy'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(cv_df,\n",
    "              y='model_name',\n",
    "              text='accuracy',\n",
    "              x='accuracy',\n",
    "              color='model_name',\n",
    "              color_discrete_sequence=paleta_dhauz,\n",
    "              template='plotly_white')\n",
    "\n",
    "fig.update_yaxes(type='category', showgrid=False)\n",
    "fig.update_xaxes(showgrid=False)\n",
    "fig.update_layout(title='Compara√ß√£o de acur√°ria dos modelos')\n",
    "fig.update_traces(textposition=\"top center\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De modo geral, percebe-se que os algoritmos produziram resultados parecidos. Tanto o SVC Linear quanto a Regress√£o Log√≠stica foram considerados para modelar nossa vari√°vel, uma vez que ambos apresentaram boas acur√°cias com baixa variabilidade. Falando um pouco sobre eles, uma diferen√ßa entre esses dois algoritmos reside em suas abordagens ‚Äì enquanto o SVC Linear se baseia em propriedades geom√©tricas dos dados e tenta maximizar a margem (vetor de suporte) entre as vari√°veis das classes, a Regress√£o Log√≠stica tem como base uma abordagem estat√≠stica e busca otimizar a probabilidade posterior da classe. Nesta case, o *LinearSVC* foi escolhido para seguir com a modelagem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Afinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A t√©cnica *GridSerchCV* ser√° utilizada para afinar os hiperpar√¢metros. Este m√©todo tamb√©m utiliza a valida√ß√£o cruzada para testar as combina√ß√µes de hiperpar√¢metros, que inclusive ser√£o poucas para essa case em espec√≠fico. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'C': [1, 0.6, 0.2, 0.01],\n",
    "    'fit_intercept': [True, False],\n",
    "}\n",
    "\n",
    "svc = LinearSVC(random_state=0, class_weight='balanced')\n",
    "\n",
    "clf = GridSearchCV(svc, params, cv=5, verbose=True, n_jobs=-1)\n",
    "\n",
    "clf = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avalia√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig = px.imshow(cm,\n",
    "                text_auto=True,\n",
    "                color_continuous_scale=px.colors.sequential.Purples,\n",
    "                title='Matriz de confus√£o')\n",
    "\n",
    "fig.update_layout(yaxis={'title':'Reais'}, \n",
    "                  xaxis={'title':'Previstos'},\n",
    "                  coloraxis_showscale=False, \n",
    "                  font_size=10,\n",
    "                  height=700)\n",
    "\n",
    "fig.update_xaxes(dtick=1)\n",
    "fig.update_yaxes(dtick=1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao avaliar o desempenho do modelo, percebe-se que a sua habilidade em classificar reservas que n√£o ser√£o canceladas √© maior. Tendo dito isso, o algoritmo conseguiu prever 73% dos cancelamentos no conjunto de teste. N√£o podemos afirmar que os custos (erros) do modelo para o problema em quest√£o s√£o de natureza muito s√©ria, mas o principal deles √© o falso negativo, que representa justamente reservas que foram canceladas sendo que o modelo classificou o contr√°rio. Algo interessante a se estimar √© o quanto esses erros estariam custando para a empresa (em termos de di√°rias perdidas). Por fim, por mais que existam maneiras de atribuir probabilidade √†s classifica√ß√µes do SVC Linear, ele √© essencialmente determin√≠stico e a perspectiva probabil√≠stica dos resultados n√£o ser√° explorada nesta case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variando o conjunto de treino/teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguindo a sugest√£o da case, os dados de 2016 ser√£o utilizados para treinar o modelo e os de 2017 para test√°-lo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.copy()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X[num_vars] = scaler.fit_transform(X[num_vars])\n",
    "\n",
    "train = X.loc[X['year_arrival_date']==2016]\n",
    "test = X.loc[X['year_arrival_date']==2017]\n",
    "\n",
    "X_train = pd.get_dummies(train[nom_vars + num_vars], columns=nom_vars)\n",
    "y_train = train['cancellation']\n",
    "\n",
    "X_test = pd.get_dummies(test[nom_vars + num_vars], columns=nom_vars)\n",
    "y_test = test['cancellation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC(random_state=0, C=0.01, fit_intercept=True, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig = px.imshow(cm,\n",
    "                text_auto=True,\n",
    "                color_continuous_scale=px.colors.sequential.Purples,\n",
    "                title='Matriz de confus√£o')\n",
    "\n",
    "fig.update_layout(yaxis={'title':'Reais'}, \n",
    "                  xaxis={'title':'Previstos'},\n",
    "                  coloraxis_showscale=False, \n",
    "                  font_size=10,\n",
    "                  height=700)\n",
    "\n",
    "fig.update_xaxes(dtick=1)\n",
    "fig.update_yaxes(dtick=1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A principal raz√£o que eu consigo pensar para se fazer tal separa√ß√£o seria se caso alguma vari√°vel temporal do conjunto apresentasse algum tipo de **sazonalidade** anual que explicasse o cancelamento das reservas. Desta maneira, tal sazonalidade permaneceria √≠ntegra durante os processos de treinamento e teste. <br>\n",
    "Al√©m do mais, como o conjunto se trata de um conjunto desbalanceado, outra raz√£o v√°lida que pode explicar esse tipo de separa√ß√£o seria o princ√≠pio da t√©cnica **filtro de dom√≠nio**, que consiste em segmentar os dados para um dom√≠nio em espec√≠fico (como um ano ou tipo de hotel X), a fim de obter amostras mais balanceadas que n√£o violem nenhum princ√≠pio de amostragem. <br>\n",
    "Tendo dito isto, a separa√ß√£o aleat√≥ria anterior expressou resultados ligeiramente melhores e a minha indica√ß√£o √© permanecer com ela. "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "295.038px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
